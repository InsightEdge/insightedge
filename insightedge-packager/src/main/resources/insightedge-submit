#!/usr/bin/env bash

if [ -z "${INSIGHTEDGE_HOME}" ]; then
  export INSIGHTEDGE_HOME="$(cd "`dirname "$0"`"/..; pwd)"
fi

# disable randomized hash for string in Python 3.3+
export PYTHONHASHSEED=0

# add datagrid and InsightEdge JARs to job --jars
. ${INSIGHTEDGE_HOME}/sbin/common-insightedge.sh
INSIGHTEDGE_JARS=$(get_libs ',')

process_args(){
    ARGUMENTS=""
    for i in "$@"
        do
            if [[ $i == "--jars" ]]; then
                ARGUMENTS+="--jars $INSIGHTEDGE_JARS,"
            else ARGUMENTS+="$i "
            fi
        done
    if [[ ! $ARGUMENTS =~ .*--jars.* ]]
    then
       # pyspark-shell arguments order is different
      if [[ $1 == "pyspark-shell-main" ]]; then
        ARGUMENTS="$ARGUMENTS --jars $INSIGHTEDGE_JARS"
      else
        ARGUMENTS=" --jars $INSIGHTEDGE_JARS $ARGUMENTS"
      fi
    fi
    echo $ARGUMENTS
}
ARGS=$(process_args "$@")

exec "${INSIGHTEDGE_HOME}"/bin/insightedge-class org.apache.spark.deploy.SparkSubmit $ARGS
